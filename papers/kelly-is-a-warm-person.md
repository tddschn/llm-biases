# “Kelly is a Warm Person, Joseph is a Role Model”: Gender Biases in LLM-Generated Reference Letters

![](https://github.com/cli/cli/assets/45612704/d5cdfbbf-6cdf-4ac9-9778-0c43fa4f2e23)

## Code

https://github.com/uclanlp/biases-llm-reference-letters

https://sourcegraph.com/github.com/uclanlp/biases-llm-reference-letters

prompt generation: https://sourcegraph.com/github.com/uclanlp/biases-llm-reference-letters/-/blob/generate_clg.py?L24=

- [“Kelly is a Warm Person, Joseph is a Role Model”: Gender Biases in LLM-Generated Reference Letters](#kelly-is-a-warm-person-joseph-is-a-role-model-gender-biases-in-llm-generated-reference-letters)
  - [Code](#code)
    - [Task, Input, Output, Significance](#task-input-output-significance)
    - [Existing Effort \& Limitation](#existing-effort--limitation)
    - [Limitation Triviality](#limitation-triviality)
    - [Challenge (If Non-Trivial)](#challenge-if-non-trivial)
    - [Proposed Solutions](#proposed-solutions)
  - [Task, Input, Output, Significance](#task-input-output-significance-1)
  - [Existing Effort \& Limitation](#existing-effort--limitation-1)
  - [Limitation Triviality](#limitation-triviality-1)
  - [Challenge (If Non-Trivial)](#challenge-if-non-trivial-1)
  - [Proposed Solutions](#proposed-solutions-1)

<details>
<summary>longer version</summary>



### Task, Input, Output, Significance
- The task addresses the critical issue of gender bias in LLMs used for writing recommendation letters.
- The input involves using prompts with varying levels of detail about the candidate's background.
- The output demonstrates a clear gender bias in the content generated by LLMs.
- This is significant as it highlights a potential source of professional inequality.

### Existing Effort & Limitation
- Existing efforts include designing evaluation methods to specifically target and reveal biases.
- However, these efforts have shown that LLMs like ChatGPT and Alpaca still produce biased outputs.

### Limitation Triviality
- The triviality of the limitation is negated by the impact these biases can have on perpetuating societal inequalities, making it a significant issue to address.

### Challenge (If Non-Trivial)
- The challenges include the complexity of societal biases that are deeply embedded in the data LLMs are trained on, and the technical difficulty in detecting and mitigating such nuanced biases.

### Proposed Solutions
- The paper proposes creating a comprehensive framework for identifying biases and suggests that future research focus on developing techniques to effectively mitigate these biases.


</details>

## Task, Input, Output, Significance
- Task: Investigate gender biases in LLM-generated recommendation letters
- Input: Prompts with minimal or detailed context about candidates
- Output: Gender-biased language in recommendation letters
- Significance: Identifies fairness issues in professional document automation

## Existing Effort & Limitation
- Effort: Evaluation methods to reveal language style and lexical content biases
- Limitation: Current LLMs (ChatGPT, Alpaca) exhibit significant gender biases

## Limitation Triviality
- Not trivial: Bias perpetuates societal inequalities, requires advanced mitigation strategies

## Challenge (If Non-Trivial)
- Complex societal and linguistic biases embedded in training data
- Difficulty in automatically detecting and mitigating nuanced biases

## Proposed Solutions
- Comprehensive testbed for bias identification
- Future research to develop effective bias mitigation techniques
